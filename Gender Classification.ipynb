{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classificaton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from scrape import get_remote_tgz_files, download_extract_files\n",
    "from parse import paths, parse_readme\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "from dbhelpers import select\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from features import sample_random_columns, extract_mfcc, extract_mfcc_as_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = '''http://www.repository.voxforge1.org/downloads/SpeechCorpus/Trunk/Audio/Main/16kHz_16bit/'''\n",
    "DATA_DIR = '''data'''\n",
    "DB = '''genderclass.db'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data\n",
    "Only files not already downloaded and extracted will be fetched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(DATA_DIR)\n",
    "urls = get_remote_tgz_files(SOURCE_URL)\n",
    "download_extract_files(urls, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DB to hold features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB)\n",
    "db = conn.cursor()\n",
    "db.execute('''DROP TABLE IF EXISTS features''')\n",
    "db.execute('''CREATE TABLE features\n",
    "                     (file text, \n",
    "                      path text, \n",
    "                      female integer, \n",
    "                      age text, \n",
    "                      language text, \n",
    "                      dialect text,\n",
    "                      cepstrum blob,\n",
    "                      n_mfcc integer,\n",
    "                      n_frames integer)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "Silence trimmed at beginning and end of each file.\n",
    "\n",
    "MFCC extracted (with default librosa settings).\n",
    "\n",
    "Save into database.\n",
    "\n",
    "(skipped 127 records due to lack of parsable readme or wav-folder, takes about 20 min to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-25 21:43:11.750068\n",
      "2019-03-25 22:04:53.244463\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "data_folder = Path(DATA_DIR)\n",
    "conn = sqlite3.connect(DB)\n",
    "db = conn.cursor()\n",
    "samples = os.listdir(data_folder)\n",
    "\n",
    "skipped = []\n",
    "for sample in samples:\n",
    "    (wav_folder, readme_path) = paths(data_folder, sample)\n",
    "\n",
    "    if(wav_folder is None or readme_path is None):\n",
    "        skipped.append(wav_folder)\n",
    "        continue;\n",
    "\n",
    "    meta = parse_readme(readme_path)\n",
    "    if(not 'gender' in meta):\n",
    "        skipped.append(wav_folder)\n",
    "        continue;\n",
    "    try:\n",
    "        wavs = os.listdir(wav_folder)\n",
    "        for wav in wavs:\n",
    "            y, fs = librosa.load(wav_folder / wav, sr=None)\n",
    "            y, idx = librosa.effects.trim(y)\n",
    "            mfcc = librosa.feature.mfcc(y, fs)\n",
    "\n",
    "            db.execute('''INSERT INTO features VALUES\n",
    "             (?,?,?,?,?,?,?,?,?)''', \n",
    "                (wav[:-4], \n",
    "                str(wav_folder), \n",
    "                meta['gender'] == 'female', \n",
    "                meta.get('age range', ''), \n",
    "                meta.get('language', ''), \n",
    "                meta.get('pronunciation dialect',''),\n",
    "                bytes(memoryview(mfcc)),\n",
    "                mfcc.shape[0],\n",
    "                mfcc.shape[1]))\n",
    "\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(wav_folder)\n",
    "        print(\"type error: \" + str(e))\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "conn.close()\n",
    "print(datetime.datetime.now())\n",
    "print(len(skipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into data sets\n",
    "Known problem: Will not return same data set every time since sqlite does not support seeded random. Should be done in python instead.\n",
    "\n",
    "Trade off: unbalanced data set with most subjects having 10 files, but there are those with a lot more (max 530). Only 430 females and over 5000 males. Optimally would be good if not same subject was present in training and test set, and if subjects were sampled to an equal representation, but this will have to do for now! (target has been equal sampling of male/female). \n",
    "\n",
    "Could create validation data set by same (improved) method if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB)\n",
    "db = conn.cursor()\n",
    "females = select('''SELECT * FROM features WHERE female == 1 ORDER BY RANDOM()''', db)\n",
    "males = select('''SELECT * FROM features WHERE female == 0 ORDER BY RANDOM() LIMIT {}'''.format(len(females)), db)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "l = int(len(females) / 2)\n",
    "\n",
    "train = (males[0:l], females[0:l])\n",
    "test = (males[l+1:2*l], females[l+1:2*l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train one GMM model per gender\n",
    "Also, clips are not the same length so a fixed number of random frames are selected per clip.\n",
    "\n",
    "Skip first coefficient since that represents average power, but normalize before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_speaker = 25\n",
    "\n",
    "models = []\n",
    "for genderdata in train:\n",
    "    features = extract_mfcc_as_rows(genderdata, frames_per_speaker)\n",
    "    \n",
    "    gmm = GMM(n_components = 8, max_iter = 200, covariance_type='diag', n_init = 3)\n",
    "    gmm.fit(features)\n",
    "    \n",
    "    models.append(gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply models to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['file', 'path', 'gender_GT', 'gender_pred']\n",
    "result = {keys[i]: [] for i in np.arange(len(keys))}\n",
    "\n",
    "n_frames = 20\n",
    "for i in range(len(test)):\n",
    "    for speaker in test[i]:\n",
    "        mfcc = extract_mfcc(speaker)\n",
    "        frames = sample_random_columns(mfcc, n_frames)\n",
    "        \n",
    "        log_likelihood = np.zeros(len(models))\n",
    "        for i in range(len(models)):\n",
    "            gmm    = models[i]  \n",
    "            log_likelihood[i] = gmm.score(frames.T)\n",
    "        \n",
    "        result['file'].append(speaker[0])\n",
    "        result['path'].append(speaker[1])\n",
    "        result['gender_GT'].append(speaker[2])\n",
    "        result['gender_pred'].append(np.argmax(log_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results\n",
    "\n",
    "Don't really have the feeling for precision and recall terminology in this case but did something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.781653\n",
      "Accuracy females: 0.714189\n",
      "Accuracy males: 0.849117\n"
     ]
    }
   ],
   "source": [
    "GT = np.asarray(result['gender_GT'])\n",
    "pred = np.asarray(result['gender_pred'])\n",
    "\n",
    "ones = np.ones(len(GT))\n",
    "zeros = np.zeros(len(GT))\n",
    "females_GT = np.equal(GT, ones)\n",
    "males_GT = np.equal(GT, zeros)\n",
    "\n",
    "accurate = np.equal(GT, pred)\n",
    "acc_fem = accurate[np.where(GT == 1)]\n",
    "acc_male = accurate[np.where(GT == 0)]\n",
    "\n",
    "print('Overall accuracy: %f' % (accurate.sum()/len(accurate)))\n",
    "print('Accuracy females: %f' % (acc_fem.sum()/len(acc_fem)))\n",
    "print('Accuracy males: %f' % (acc_male.sum()/len(acc_male)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPython.display.Audio(y, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional comments\n",
    "\n",
    "ML:\n",
    "- Make use of other features from README - potentially other classification methods\n",
    "- Narrower frames of e.g. 25 ms\n",
    ">spec = librosa.feature.melspectrogram(y=y, sr=fs, S=None, n_fft=400, hop_length=160, power=2.0)\n",
    ">mfcc1 = librosa.feature.mfcc(y, fs, S=numpy.log(spec))\n",
    "- Train gmm bic/aic with validation data set for n_components \n",
    "\n",
    "Coding:\n",
    "- Error and type checks in functions, can really only be used in known context\n",
    "- Latter workbook cells not independent, should use db/files between cells and not variables\n",
    "- Absolutely could make use of some testing :)\n",
    "\n",
    "Loose thoughts:\n",
    "- Fit one gmm per class instead of one gaussian per class and evalate likelihood since there the MFCCs per gender wont be one gaussian each? Could then just have used median frequency?\n",
    "\n",
    "Some sources and inspiration on the way:\n",
    "- https://appliedmachinelearning.blog/2017/06/14/voice-gender-detection-using-gmms-a-python-primer/\n",
    "- GENDER EFFECTS IN SPEAKER RECOGNITION - J.S. Mason & J. Thompson\n",
    "- https://www.astroml.org/book_figures/chapter4/fig_GMM_1D.html\n",
    "- Gender identification of a speaker using MFCC and GMM - Conference Paper · November 2013 - Ergün Yücesoy & Vasif Nabiyev\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
